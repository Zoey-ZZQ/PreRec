# SVD概述

## SVD概念

- 奇异值：奇异值和矩阵的特征值有关系。这里的奇异值Data*DataT特征值的平方根。
- 奇异值分解：SVD是矩阵分解的一种类型，用于提取信息，可以把SVD看成是从噪声数据中抽取相关特征。SVD将原始的数据集矩阵Data分解成三个矩阵U、Σ和VT。
$$
Data_{m*n} = U_{m*m} Σ_{m*n} VT_{n*n}
$$
上述分解构造出一个矩阵Σ即为奇异值矩阵，该矩阵只有对角元素，其余元素均为0。这些对角元素由大到小排列，对应了原始数据矩阵Data的奇异值。U通常是项目矩阵，VT通常是用户矩阵。

## 奇异值数目

在科学和工程中，一直存在这样一个普遍事实：在某个奇异值的数目（r个）之后，其他的奇异值都置为0。这就意味着数据集中仅有r个重要特征，而其余特征则都是噪声或冗余特征。确定要保留的奇异值的数目有很多启发式的策略，其中一个典型的做法就是保留矩阵中90%的能量信息。为了计算总能量信息，我们将所有的奇异值求其平方和。于是可以将奇异值的平方和累加到总值的90%为止。

## SVD降维

确定奇异值数目后，奇异值矩阵就会变为一个小很多的对角矩阵。例如取奇异值为3，那么上述矩阵Data就可以被近似为：
D a t a m ∗ n = U m ∗ 3 Σ 3 ∗ 3 V T 3 ∗ n Data_{m*n}=U_{m*3}Σ_{3*3} VT_{3*n}*D**a**t**a**m*∗*n*​=*U**m*∗3​Σ3∗3​*V**T*3∗*n*​
![在这里插入图片描述](https://img-blog.csdnimg.cn/20200821112558953.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ1MzM0Nzg5,size_16,color_FFFFFF,t_70#pic_center)

SVD分解：

```python
from numpy import *

Data =  [[1, 1, 1, 0, 0],
         [2, 2, 2, 0, 0],
         [1, 1, 1, 0, 0],
         [5, 5, 5, 0, 0],
         [1, 1, 0, 2, 2],
         [0, 0, 0, 3, 3],
         [0, 0, 0, 1, 1]]

U,Sigma,VT = linalg.svd(Data)
print(Sigma)
#[9.72140007e+00 5.29397912e+00 6.84226362e-01 1.50962387e-15 1.15387192e-31]后两个太小舍去
12345678910111213
```

重构原始矩阵：

```python
#构造奇异值矩阵
Sig3 = mat([[Sigma[0],0,0],[0,Sigma[1],0],[0,0,Sigma[2]]])

U[:,:3]*Sig3*VT[:3,:]
'''
matrix([[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00,
 -2.84366098e-16, -2.94015497e-16],
        [ 2.00000000e+00,  2.00000000e+00,  2.00000000e+00,
          4.47489534e-16,  4.28190736e-16],
        [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00,
          3.09573758e-16,  2.99924358e-16],
        [ 5.00000000e+00,  5.00000000e+00,  5.00000000e+00,
         -1.47703573e-16, -1.95842150e-16],
        [ 1.00000000e+00,  1.00000000e+00, -5.70229711e-16,
          2.00000000e+00,  2.00000000e+00],
        [-7.49390630e-17,  9.96896569e-16, -1.34350906e-15,
          3.00000000e+00,  3.00000000e+00],
        [-8.18314124e-17,  2.75447132e-16, -3.13743829e-16,
          1.00000000e+00,  1.00000000e+00]])
'''
1234567891011121314151617181920
```

## SVD应用

- 隐性语义索引（Latent Semantic Indexing,LSI）或隐性语义分析（Latent Semantic Analysis, LSA）

  在LSI中，一个矩阵是由文档和词语组成的。当我们在该矩阵上应用SVD时，就会构建出多个奇异值。这些奇异值代表了文档中的概念或主题，这一特点可以用于更高效的文档搜索。

- 推荐系统

# 基于协同过滤的推荐系统

协同过滤（collaborative filtering）：通过将用户和其他用户的数据进行对比来实现推荐的。进行对比就需要用到相似度计算方法。

## 相似度计算

协同过滤的相似度计算不关心物品的描述属性，而是根据用户对物品的评分计算物品相似度。

- 欧氏距离 通过 相似度=1/（1+距离） 将相似度值归一化到0-1之间

  ```python
  def eulidSim(inA, inB):
      return 1.0 / (1.0 + la.norm(inA - inB))
  12
  ```

- 皮尔逊相关系数（Pearson correlation） 在Numpy中通过corrcoef()进行。该方法相对于欧氏距离的一个优势在于，它对用户评级的量级并不敏感。尔逊相关系数的取值范围从-1到+1，我们通过0.5 + 0.5＊corrcoef()这个函数计算，并且把其取值范围归一化到0到1之间。

  ```python
  def pearsSim(inA, inB):
      if len(inA) < 3:
          return 1.0
      return 0.5 + 0.5 * corrcoef(inA, inB, rowvar=0)[0][1] 
  1234
  ```

- 余弦相似度（cosine similarity）

  ```python
  def cosSim(inA, inB):
      num = float(inA.T * inB)
      denom = la.norm(inA) * la.norm(inB)
      return 0.5 + 0.5 * (num / denom)
  1234
  ```

## 推荐引擎的评价

通常用于推荐引擎评价的指标是称为最小均方根误差（Root MeanSquared Error, RMSE）的指标，它首先计算均方误差的平均值然后取其平方根。如果评级在1星到5星这个范围内，而我们得到的RMSE为1.0，那么就意味着我们的预测值和用户给出的真实评价相差了一个星级。

## 餐馆菜肴推荐引擎

1. 寻找用户没有评过分的物品，即用户-物品矩阵中用户行的0值
2. 根据向相似度计算对未评过分的物品预测一个可能的评分
3. 对未评分物品的预测评分从高到低排行，返回前N个物品推荐给用户

```python
#相似度估计方法
def loadExData():
    return [[1, 1, 0, 2, 2],
            [0, 0, 0, 3, 3],
            [0, 0, 0, 1, 1],
            [1, 1, 1, 0, 0],
            [2, 2, 2, 0, 0],
            [1, 1, 1, 0, 0],
            [5, 5, 5, 0, 0]]
            
def standEst(dataMat, user, simMeas, item):
    '''
    函数说明：相似度估计方法
    :param dataMat:数据矩阵
    :param user:用户编号
    :param simMeas:相似度计算方法
    :param item:物品编号
    :return:
    '''
    n = shape(dataMat)[1]  # 物品数目
    simTotal = 0.0; ratSimTotal = 0.0  # 初始化

    # 对列进行遍历，计算物品相似度
    for j in range(n):
        userRating = dataMat[user, j]
        # 如果用户没有对该物品评分，跳过
        if userRating == 0:
            continue

        overLap = np.nonzero(np.logical_and(dataMat[:, item].A > 0, dataMat[:, j].A > 0))[0]
        '''
        nonzero(a)函数一般返回两行arrary。如果mat()一下，就是2*n的矩阵，其中n是矩阵a中不为0的元素个数
        第一个array表示非零元素所在行，第二个array表示非零元素所在列，分别取对应位置的值组成非零元素的坐标。
        '''
        if len(overLap) == 0:
            similarity = 0
        else:
            similarity = simMeas(dataMat[overLap, item],
                                 dataMat[overLap, j])
        print('物品 %d 和 物品 %d 的相似度是：%f' % (item, j, similarity))

        simTotal += similarity  # 总的相似度
        ratSimTotal += similarity * userRating  # 考虑用户评分

    if simTotal == 0:
        return 0
    else:
        return ratSimTotal / simTotal  # 对相似度评分进行归一化，使得评分值在0到5之间
    
    
#基于协同过滤的推荐引擎
def recommend(dataMat, user, N=3, simMeas=cosSim, estMethod=standEst):
    '''
    函数说明：产生最高的N个函数推荐结果
    :param dataMat,user,simMeas:调用standEst()函数
    :param N:N个推荐结果
    :param estMethod:相似度估计方法
    :return:
    '''
    # 寻找用户未评分的物品
    unratedItems = np.nonzero(dataMat[user, :].A == 0)[1]
    if len(unratedItems) == 0:
        return '你对所有物品都评过分'

    itemScores = []  # 未评分物品列表
    for item in unratedItems:
        estimatedScore = estMethod(dataMat, user, simMeas, item)
        itemScores.append((item, estimatedScore))
    return sorted(itemScores, key=lambda jj: jj[1], reverse=True)[:N]
123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869
```

【实验】：

```python
In:recommend(myMat, 2)
Out:物品 1 和 物品 0 的相似度是：1.000000
	物品 1 和 物品 3 的相似度是：0.928746
	物品 1 和 物品 4 的相似度是：1.000000
	物品 2 和 物品 0 的相似度是：1.000000
	物品 2 和 物品 3 的相似度是：1.000000
	物品 2 和 物品 4 的相似度是：0.000000
	[(2, 2.5), (1, 2.0243290220056256)]
12345678
```

表明在指定相似度计算方法为余弦相似度时，用户2对物品2的预测评分为2.5，对物品1的预测评分为2.02

- 利用SVD提高推荐效果

```python
#基于svd的相似度估计方法
def loadExData2():
    return [[2, 0, 0, 4, 4, 0, 0, 0, 0, 0, 0],
            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5],
            [0, 0, 0, 0, 0, 0, 0, 1, 0, 4, 0],
            [3, 3, 4, 0, 3, 0, 0, 2, 2, 0, 0],
            [5, 5, 5, 0, 0, 0, 0, 0, 0, 0, 0],
            [0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0],
            [4, 0, 4, 0, 0, 0, 0, 0, 0, 0, 5],
            [0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 4],
            [0, 0, 0, 0, 0, 0, 5, 0, 0, 5, 0],
            [0, 0, 0, 3, 0, 0, 0, 0, 4, 5, 0],
            [1, 1, 2, 1, 1, 2, 1, 0, 4, 5, 0]]
            
def svdEst(dataMat, user, simMeas, item):
    n = shape(dataMat)[1]
    simTotal = 0.0; ratSimTotal = 0.0

    # 奇异值分解
    U, Sigma, VT = la.svd(dataMat)
    # 构建对角矩阵
    Sig4 = mat(np.eye(4) * Sigma[:4])
    '''
    np.eye(N, M=None, k=0)返回一个对角线元素全是1，其余元素全为0的二维array
    N是行数，M是列数（默认等于行数），k是对角线的位置（+1右移-1左移）
    '''
    # 将物品转换到低维空间
    xformedItems = dataMat.T * U[:, :4] * Sig4.I

    #对行进行遍历，计算物品相似度
    for j in range(n):
        userRating = dataMat[user, j]
        if userRating == 0 or j == item:
            continue
        similarity = simMeas(xformedItems[item, :].T,
                             xformedItems[j, :].T)
        print('物品 %d 和 物品 %d 的相似度是： %f' % (item, j, similarity))

        simTotal += similarity
        ratSimTotal += similarity * userRating

    if simTotal == 0:
        return 0
    else:
        return ratSimTotal / float(simTotal)
123456789101112131415161718192021222324252627282930313233343536373839404142434445
```

【实验】：不做svd分解和做svd分解的推荐结果比较：

```python
In[1]:recommend(myMat, 2, estMethod=svdEst)
Out[1]: 物品 0 和 物品 7 的相似度是： 0.892120
		物品 0 和 物品 9 的相似度是： 0.468911
		物品 1 和 物品 7 的相似度是： 0.923647
		物品 1 和 物品 9 的相似度是： 0.479048
		物品 2 和 物品 7 的相似度是： 0.874279
		物品 2 和 物品 9 的相似度是： 0.494118
		物品 3 和 物品 7 的相似度是： 0.689557
		物品 3 和 物品 9 的相似度是： 0.623806
		物品 4 和 物品 7 的相似度是： 0.857733
		物品 4 和 物品 9 的相似度是： 0.531780
		物品 5 和 物品 7 的相似度是： 0.383370
		物品 5 和 物品 9 的相似度是： 0.620292
		物品 6 和 物品 7 的相似度是： 0.428954
		物品 6 和 物品 9 的相似度是： 0.824318
		物品 8 和 物品 7 的相似度是： 0.757170
		物品 8 和 物品 9 的相似度是： 0.736114
		物品 10 和 物品 7 的相似度是： 0.322192
		物品 10 和 物品 9 的相似度是： 0.496642
		[(6, 2.973198759025347), (5, 2.8540856936429773), (10, 2.819569680907716)]
In[2]:recommend(myMat, 2, estMethod=standEst)
Out[2]: 物品 0 和 物品 7 的相似度是：1.000000
		物品 0 和 物品 9 的相似度是：1.000000
		物品 1 和 物品 7 的相似度是：1.000000
		物品 1 和 物品 9 的相似度是：1.000000
		物品 2 和 物品 7 的相似度是：1.000000
		物品 2 和 物品 9 的相似度是：1.000000
		物品 3 和 物品 7 的相似度是：0.000000
		物品 3 和 物品 9 的相似度是：0.947214
		物品 4 和 物品 7 的相似度是：1.000000
		物品 4 和 物品 9 的相似度是：1.000000
		物品 5 和 物品 7 的相似度是：0.000000
		物品 5 和 物品 9 的相似度是：1.000000
		物品 6 和 物品 7 的相似度是：0.000000
		物品 6 和 物品 9 的相似度是：0.944649
		物品 8 和 物品 7 的相似度是：1.000000
		物品 8 和 物品 9 的相似度是：1.000000
		物品 10 和 物品 7 的相似度是：0.000000
		物品 10 和 物品 9 的相似度是：0.000000
		[(3, 4.0), (5, 4.0), (6, 4.0)]

1234567891011121314151617181920212223242526272829303132333435363738394041
```

# 基于SVD的图像压缩

利用SVD对数字图像进行压缩，允许基于任意给定的奇异值数目来重构图像。

```python
#打印矩阵
def printMat(inMat, thresh=0.8):
    '''
    函数说明：打印矩阵
    :param inMat: 输入的1024像素的图像
    :param thresh: 阈值，界定图像深色和浅色
    :return:
    '''
    for i in range(32):
        for j in range(32):
            if float(inMat[i, j]) > thresh:
                print(1, end='')
            else:
                print(0, end='')
        print('')

#图像压缩
def imgCompress(numSV=3, thresh=0.8):
    '''
    函数说明：图像压缩，基于任意给定的奇异值数目来重构图像
    :param numSV: 奇异值数目
    :param thresh:阈值
    :return:
    '''
    #从文本文件中以数值的方式读入字符
    my1 = []
    for line in open('0_5.txt').readlines():
        newRow = []
        for i in range(32):
            newRow.append(int(line[i]))
        my1.append(newRow)
    myMat = np.mat(my1)

    print('***原始矩阵***')
    #打印原始数据

    printMat(myMat, thresh)
    #svd分解
    U, Sigma, VT = la.svd(myMat)

    SigRecon = np.mat(np.zeros((numSV, numSV)))     #构建由奇异值组成对角矩阵
    for k in range(numSV):
        SigRecon[k, k] = Sigma[k]

    reconMat = U[:, :numSV] * SigRecon * VT[:numSV, :]      #重构矩阵
    print('***用 %d 个奇异值重构矩阵***' % numSV)
    printMat(reconMat, thresh)
1234567891011121314151617181920212223242526272829303132333435363738394041424344454647
In:imgCompress()
Out:***原始矩阵***
	00000000000000110000000000000000
	00000000000011111100000000000000
	00000000000111111110000000000000
	00000000001111111111000000000000
	00000000111111111111100000000000
	00000001111111111111110000000000
	00000000111111111111111000000000
	00000000111111100001111100000000
	00000001111111000001111100000000
	00000011111100000000111100000000
	00000011111100000000111110000000
	00000011111100000000011110000000
	00000011111100000000011110000000
	00000001111110000000001111000000
	00000011111110000000001111000000
	00000011111100000000001111000000
	00000001111100000000001111000000
	00000011111100000000001111000000
	00000001111100000000001111000000
	00000001111100000000011111000000
	00000000111110000000001111100000
	00000000111110000000001111100000
	00000000111110000000001111100000
	00000000111110000000011111000000
	00000000111110000000111111000000
	00000000111111000001111110000000
	00000000011111111111111110000000
	00000000001111111111111110000000
	00000000001111111111111110000000
	00000000000111111111111000000000
	00000000000011111111110000000000
	00000000000000111111000000000000
	***用 3 个奇异值重构矩阵***
	00000000000000000000000000000000
	00000000000000000000000000000000
	00000000000010111110000000000000
	00000000000011111110000000000000
	00000000000111111111000000000000
	00000000001111111111110000000000
	00000000001111111111110000000000
	00000000011100000000111000000000
	00000000111100000000111100000000
	00000001111100000000111100000000
	00000001111100000000011100000000
	00000001111100000000011100000000
	00000001111100000000011100000000
	00000000111100000000001111000000
	00000000111100000000001111000000
	00000000111100000000001111000000
	00000000111100000000001111000000
	00000000111100000000001111000000
	00000000111100000000001111000000
	00000000111100000000001110000000
	00000000111100000000001111000000
	00000000111100000000001111000000
	00000000111100000000001111000000
	00000000111100000000001111000000
	00000000111100000000001110000000
	00000000111100000000111100000000
	00000000001111111111111000000000
	00000000001111111111110000000000
	00000000001111111111110000000000
	00000000000011111111110000000000
	00000000000011111111100000000000
	00000000000000000000000000000000
```
